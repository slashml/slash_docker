{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e56314e-c0bd-489e-808d-74a72323b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slashdocker import save_model, run_model_server, stop_model_server\n",
    "import truss\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194bbf52-40bc-461e-8005-9cdd281c5298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "data = [[1], [2], [3]]\n",
    "lm.fit(data, [2, 4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65cce944-73ab-43c8-b853-80c21dc43e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.predict([[9]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aad0e44d-ff4f-4546-a05f-0d70fc86a51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5df78c-d615-4199-b4c6-3ebd7833de3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'apply_library_patches': True,\n",
      "            'base_image': None,\n",
      "            'bundled_packages_dir': 'packages',\n",
      "            'data_dir': 'data',\n",
      "            'description': None,\n",
      "            'environment_variables': {},\n",
      "            'examples_filename': 'examples.yaml',\n",
      "            'external_data': None,\n",
      "            'external_package_dirs': [],\n",
      "            'input_type': 'Any',\n",
      "            'live_reload': False,\n",
      "            'model_class_filename': 'model.py',\n",
      "            'model_class_name': 'Model',\n",
      "            'model_framework': <ModelFrameworkType.SKLEARN: 'sklearn'>,\n",
      "            'model_metadata': {'model_binary_dir': 'model',\n",
      "                               'supports_predict_proba': False},\n",
      "            'model_module_dir': 'model',\n",
      "            'model_name': None,\n",
      "            'model_type': 'Model',\n",
      "            'python_version': 'py310',\n",
      "            'requirements': ['threadpoolctl==3.2.0',\n",
      "                             'scipy==1.11.3',\n",
      "                             'joblib==1.3.2',\n",
      "                             'numpy==1.23.5',\n",
      "                             'scikit-learn==1.3.1'],\n",
      "            'resources': Resources(cpu='500m',\n",
      "                                   memory='512Mi',\n",
      "                                   use_gpu=False,\n",
      "                                   accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                               count=0)),\n",
      "            'secrets': {},\n",
      "            'spec_version': '2.0',\n",
      "            'system_packages': [],\n",
      "            'train': Train(training_class_filename='train.py',\n",
      "                           training_class_name='Train',\n",
      "                           training_module_dir='train',\n",
      "                           variables={},\n",
      "                           resources=Resources(cpu='500m',\n",
      "                                               memory='512Mi',\n",
      "                                               use_gpu=False,\n",
      "                                               accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                                           count=0)))}}\n"
     ]
    }
   ],
   "source": [
    "tr = save_model(lm, 'test_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "202f8b62-a4c0-4915-abc1-96dfdf85ee76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'model_framework': <ModelFrameworkType.SKLEARN: 'sklearn'>,\n",
       "  'model_type': 'Model',\n",
       "  'model_name': None,\n",
       "  'model_module_dir': 'model',\n",
       "  'model_class_filename': 'model.py',\n",
       "  'model_class_name': 'Model',\n",
       "  'data_dir': 'data',\n",
       "  'external_data': None,\n",
       "  'input_type': 'Any',\n",
       "  'model_metadata': {'model_binary_dir': 'model',\n",
       "   'supports_predict_proba': False},\n",
       "  'requirements': ['numpy==1.23.5',\n",
       "   'scipy==1.11.3',\n",
       "   'joblib==1.3.2',\n",
       "   'scikit-learn==1.3.1',\n",
       "   'threadpoolctl==3.2.0'],\n",
       "  'system_packages': [],\n",
       "  'environment_variables': {},\n",
       "  'resources': Resources(cpu='500m', memory='512Mi', use_gpu=False, accelerator=AcceleratorSpec(accelerator=None, count=0)),\n",
       "  'python_version': 'py310',\n",
       "  'examples_filename': 'examples.yaml',\n",
       "  'secrets': {},\n",
       "  'description': None,\n",
       "  'bundled_packages_dir': 'packages',\n",
       "  'external_package_dirs': [],\n",
       "  'live_reload': False,\n",
       "  'apply_library_patches': True,\n",
       "  'spec_version': '2.0',\n",
       "  'train': Train(training_class_filename='train.py', training_class_name='Train', training_module_dir='train', variables={}, resources=Resources(cpu='500m', memory='512Mi', use_gpu=False, accelerator=AcceleratorSpec(accelerator=None, count=0))),\n",
       "  'base_image': None}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9b0044-8813-4e96-a63a-2985f1895934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'apply_library_patches': True,\n",
      "            'base_image': None,\n",
      "            'bundled_packages_dir': 'packages',\n",
      "            'data_dir': 'data',\n",
      "            'description': None,\n",
      "            'environment_variables': {},\n",
      "            'examples_filename': 'examples.yaml',\n",
      "            'external_data': None,\n",
      "            'external_package_dirs': [],\n",
      "            'input_type': 'Any',\n",
      "            'live_reload': False,\n",
      "            'model_class_filename': 'model.py',\n",
      "            'model_class_name': 'Model',\n",
      "            'model_framework': <ModelFrameworkType.SKLEARN: 'sklearn'>,\n",
      "            'model_metadata': {'model_binary_dir': 'model',\n",
      "                               'supports_predict_proba': False},\n",
      "            'model_module_dir': 'model',\n",
      "            'model_name': None,\n",
      "            'model_type': 'Model',\n",
      "            'python_version': 'py310',\n",
      "            'requirements': ['numpy==1.23.5',\n",
      "                             'scipy==1.11.3',\n",
      "                             'joblib==1.3.2',\n",
      "                             'scikit-learn==1.3.1',\n",
      "                             'threadpoolctl==3.2.0'],\n",
      "            'resources': Resources(cpu='500m',\n",
      "                                   memory='512Mi',\n",
      "                                   use_gpu=False,\n",
      "                                   accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                               count=0)),\n",
      "            'secrets': {},\n",
      "            'spec_version': '2.0',\n",
      "            'system_packages': [],\n",
      "            'train': Train(training_class_filename='train.py',\n",
      "                           training_class_name='Train',\n",
      "                           training_module_dir='train',\n",
      "                           variables={},\n",
      "                           resources=Resources(cpu='500m',\n",
      "                                               memory='512Mi',\n",
      "                                               use_gpu=False,\n",
      "                                               accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                                           count=0)))}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "pp(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11dfe786-c26b-49cc-9ebb-05cf5978a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee555d53-3820-4805-b2a0-8e3ad9ffb63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 1.18kB 0.0s done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load .dockerignore\n",
      "#2 transferring context: 2B 0.0s done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/baseten/truss-server-base:3.9-v0.4.8\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [ 1/11] FROM docker.io/baseten/truss-server-base:3.9-v0.4.8\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 49.28kB done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [ 3/11] RUN python3 -c \"import sys; sys.exit(0) if sys.version_info.major == 3 and sys.version_info.minor >=8 and sys.version_info.minor <=11 else sys.exit(1)\"     || { echo \"ERROR: Supplied base image does not have 3.8 <= python <= 3.11\"; exit 1; }\n",
      "#6 CACHED\n",
      "\n",
      "#7 [ 2/11] RUN grep -w 'ID=debian\\|ID_LIKE=debian' /etc/os-release || { echo \"ERROR: Supplied base image is not a debian image\"; exit 1; }\n",
      "#7 CACHED\n",
      "\n",
      "#8 [ 4/11] RUN pip install --upgrade pip --no-cache-dir     && rm -rf /root/.cache/pip\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ 5/11] COPY ./requirements.txt requirements.txt\n",
      "#9 DONE 0.0s\n",
      "\n",
      "#10 [ 6/11] RUN pip install -r requirements.txt --no-cache-dir && rm -rf /root/.cache/pip\n",
      "#10 2.159 Collecting threadpoolctl==3.2.0 (from -r requirements.txt (line 1))\n",
      "#10 2.307   Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "#10 3.096 Collecting scipy==1.11.3 (from -r requirements.txt (line 2))\n",
      "#10 3.133   Downloading scipy-1.11.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "#10 3.168      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.4/60.4 kB 3.1 MB/s eta 0:00:00\n",
      "#10 3.364 Collecting joblib==1.3.2 (from -r requirements.txt (line 3))\n",
      "#10 3.389   Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "#10 4.636 Collecting numpy==1.23.5 (from -r requirements.txt (line 4))\n",
      "#10 4.685   Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "#10 12.81      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 2.1 MB/s eta 0:00:00\n",
      "#10 13.88 Collecting scikit-learn==1.3.1 (from -r requirements.txt (line 5))\n",
      "#10 13.91   Downloading scikit_learn-1.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "#10 14.44 Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "#10 14.48 Downloading scipy-1.11.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.6 MB)\n",
      "#10 31.90    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.6/36.6 MB 2.1 MB/s eta 0:00:00\n",
      "#10 31.94 Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "#10 32.10    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.2/302.2 kB 2.1 MB/s eta 0:00:00\n",
      "#10 32.14 Downloading scikit_learn-1.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "#10 37.32    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 2.1 MB/s eta 0:00:00\n",
      "#10 39.97 Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "#10 40.05   Attempting uninstall: numpy\n",
      "#10 40.05     Found existing installation: numpy 1.24.3\n",
      "#10 40.35     Uninstalling numpy-1.24.3:\n",
      "#10 40.97       Successfully uninstalled numpy-1.24.3\n",
      "#10 49.85   Attempting uninstall: joblib\n",
      "#10 49.85     Found existing installation: joblib 1.2.0\n",
      "#10 49.91     Uninstalling joblib-1.2.0:\n",
      "#10 50.00       Successfully uninstalled joblib-1.2.0\n",
      "#10 73.62 Successfully installed joblib-1.3.2 numpy-1.23.5 scikit-learn-1.3.1 scipy-1.11.3 threadpoolctl-3.2.0\n",
      "#10 73.62 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#10 DONE 74.3s\n",
      "\n",
      "#11 [ 7/11] WORKDIR /app\n",
      "#11 DONE 0.0s\n",
      "\n",
      "#12 [ 8/11] COPY ./data /app/data\n",
      "#12 DONE 0.0s\n",
      "\n",
      "#13 [ 9/11] COPY ./server /app\n",
      "#13 DONE 0.0s\n",
      "\n",
      "#14 [10/11] COPY ./model /app/model\n",
      "#14 DONE 0.0s\n",
      "\n",
      "#15 [11/11] COPY ./config.yaml /app/config.yaml\n",
      "#15 DONE 0.0s\n",
      "\n",
      "#16 exporting to image\n",
      "#16 exporting layers\n",
      "#16 exporting layers 0.6s done\n",
      "#16 writing image sha256:eb563028d02bd1cca299018d46a865b66f11b09c38996c0c986a901d9a92711c done\n",
      "#16 naming to docker.io/library/sklearn-model:latest done\n",
      "#16 DONE 0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model server started on port 8080, docker container id 5b9049f0cff8ae64603c82adf06567d990ffbfe5e7499e91b85e10e4a87620ab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:truss.truss_handle:Model server started on port 8080, docker container id 5b9049f0cff8ae64603c82adf06567d990ffbfe5e7499e91b85e10e4a87620ab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container state: DockerStates.RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:truss.truss_handle:Container state: DockerStates.RUNNING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "python_on_whales.Container(id='5b9049f0cff8', name='infallible_brahmagupta')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_server('test_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c902215a-77bd-447e-9bea-ff21cab029b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [37.99999999999999]}"
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1:8080/v1/models/model:predict -d '[[19]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df63aa44-4d3d-426a-9166-253586f55ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_model_server('5b9049f0cff8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e3d79-37ef-4cf2-815d-e9525e1c9ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949b8d8-247b-4084-8b01-5cc575b75182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1641fa00-15eb-4a68-8005-04b78d45b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slashdocker import save_model, run_model_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5242d25-f700-464c-8132-e935cf434ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7609636-f32e-4739-bce2-1fa70f79f3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm2 = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7185465-8de9-4fad-98fd-fd4ab4155a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.5164636969566345,\n",
       "  'token': 3910,\n",
       "  'token_str': 'founder',\n",
       "  'sequence': 'steve jobs is the founder of apple'},\n",
       " {'score': 0.36049818992614746,\n",
       "  'token': 5766,\n",
       "  'token_str': 'ceo',\n",
       "  'sequence': 'steve jobs is the ceo of apple'},\n",
       " {'score': 0.049299854785203934,\n",
       "  'token': 2343,\n",
       "  'token_str': 'president',\n",
       "  'sequence': 'steve jobs is the president of apple'},\n",
       " {'score': 0.02111203595995903,\n",
       "  'token': 8543,\n",
       "  'token_str': 'creator',\n",
       "  'sequence': 'steve jobs is the creator of apple'},\n",
       " {'score': 0.008550191298127174,\n",
       "  'token': 2269,\n",
       "  'token_str': 'father',\n",
       "  'sequence': 'steve jobs is the father of apple'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2('steve jobs is the [MASK] of apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae810874-fda6-400e-95f6-5f63a0271ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'apply_library_patches': True,\n",
      "            'base_image': None,\n",
      "            'bundled_packages_dir': 'packages',\n",
      "            'data_dir': 'data',\n",
      "            'description': None,\n",
      "            'environment_variables': {},\n",
      "            'examples_filename': 'examples.yaml',\n",
      "            'external_data': None,\n",
      "            'external_package_dirs': [],\n",
      "            'input_type': 'Any',\n",
      "            'live_reload': False,\n",
      "            'model_class_filename': 'model.py',\n",
      "            'model_class_name': 'Model',\n",
      "            'model_framework': <ModelFrameworkType.HUGGINGFACE_TRANSFORMER: 'huggingface_transformer'>,\n",
      "            'model_metadata': {'has_hybrid_args': False,\n",
      "                               'has_named_args': False,\n",
      "                               'transformer_config': {'model': 'bert-base-uncased'}},\n",
      "            'model_module_dir': 'model',\n",
      "            'model_name': None,\n",
      "            'model_type': 'fill-mask',\n",
      "            'python_version': 'py310',\n",
      "            'requirements': ['transformers==4.34.1'],\n",
      "            'resources': Resources(cpu='500m',\n",
      "                                   memory='512Mi',\n",
      "                                   use_gpu=False,\n",
      "                                   accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                               count=0)),\n",
      "            'secrets': {},\n",
      "            'spec_version': '2.0',\n",
      "            'system_packages': [],\n",
      "            'train': Train(training_class_filename='train.py',\n",
      "                           training_class_name='Train',\n",
      "                           training_module_dir='train',\n",
      "                           variables={},\n",
      "                           resources=Resources(cpu='500m',\n",
      "                                               memory='512Mi',\n",
      "                                               use_gpu=False,\n",
      "                                               accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                                           count=0)))}}\n"
     ]
    }
   ],
   "source": [
    "save_model(lm2, 'bert_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685413d-7a61-4e23-a6b4-cff54cd0c1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [internal] load .dockerignore\n",
      "#1 transferring context: 2B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load build definition from Dockerfile\n",
      "#2 transferring dockerfile: 1.33kB done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/baseten/truss-server-base:3.9-v0.4.8\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [ 1/13] FROM docker.io/baseten/truss-server-base:3.9-v0.4.8\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 51.24kB done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [ 3/13] RUN python3 -c \"import sys; sys.exit(0) if sys.version_info.major == 3 and sys.version_info.minor >=8 and sys.version_info.minor <=11 else sys.exit(1)\"     || { echo \"ERROR: Supplied base image does not have 3.8 <= python <= 3.11\"; exit 1; }\n",
      "#6 CACHED\n",
      "\n",
      "#7 [ 2/13] RUN grep -w 'ID=debian\\|ID_LIKE=debian' /etc/os-release || { echo \"ERROR: Supplied base image is not a debian image\"; exit 1; }\n",
      "#7 CACHED\n",
      "\n",
      "#8 [ 4/13] RUN pip install --upgrade pip --no-cache-dir     && rm -rf /root/.cache/pip\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ 5/13] COPY ./server_requirements.txt server_requirements.txt\n",
      "#9 DONE 0.0s\n",
      "\n",
      "#10 [ 6/13] RUN pip install -r server_requirements.txt --no-cache-dir && rm -rf /root/.cache/pip\n",
      "#10 2.771 Collecting transformers (from -r server_requirements.txt (line 3))\n",
      "#10 2.907   Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "#10 2.969      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.1/123.1 kB 2.7 MB/s eta 0:00:00\n",
      "#10 3.287 Collecting torch (from -r server_requirements.txt (line 4))\n",
      "#10 3.334   Downloading torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "#10 6.328 Collecting filelock (from transformers->-r server_requirements.txt (line 3))\n",
      "#10 6.352   Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "#10 6.622 Collecting huggingface-hub<1.0,>=0.16.4 (from transformers->-r server_requirements.txt (line 3))\n",
      "#10 6.650   Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "#10 6.661 Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers->-r server_requirements.txt (line 3)) (1.24.3)\n",
      "#10 6.833 Collecting packaging>=20.0 (from transformers->-r server_requirements.txt (line 3))\n",
      "#10 6.858   Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "#10 6.864 Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers->-r server_requirements.txt (line 3)) (6.0)\n",
      "#10 9.495 Collecting regex!=2019.12.17 (from transformers->-r server_requirements.txt (line 3))\n",
      "#10 9.554   Downloading regex-2023.10.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "#10 9.574      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 27.7 MB/s eta 0:00:00\n",
      "#10 9.585 Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from transformers->-r server_requirements.txt (line 3)) (2.31.0)\n",
      "#10 10.65 Collecting tokenizers<0.15,>=0.14 (from transformers->-r server_requirements.txt (line 3))\n",
      "#10 10.69   Downloading tokenizers-0.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "#10 11.24 Collecting safetensors>=0.3.1 (from transformers->-r server_requirements.txt (line 3))\n",
      "#10 11.28   Downloading safetensors-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "#10 11.74 Collecting tqdm>=4.27 (from transformers->-r server_requirements.txt (line 3))\n",
      "#10 11.77   Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "#10 11.80      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.6/57.6 kB 2.9 MB/s eta 0:00:00\n",
      "#10 12.01 Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch->-r server_requirements.txt (line 4)) (4.6.3)\n",
      "#10 12.16 Collecting sympy (from torch->-r server_requirements.txt (line 4))\n",
      "#10 12.19   Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "#10 14.92      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 2.1 MB/s eta 0:00:00\n",
      "#10 15.39 Collecting networkx (from torch->-r server_requirements.txt (line 4))\n",
      "#10 15.41   Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "#10 15.56 Collecting jinja2 (from torch->-r server_requirements.txt (line 4))\n",
      "#10 15.58   Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "#10 15.65      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 2.2 MB/s eta 0:00:00\n",
      "#10 15.86 Collecting fsspec (from torch->-r server_requirements.txt (line 4))\n",
      "#10 15.89   Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "#10 15.97 Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r server_requirements.txt (line 4))\n",
      "#10 16.01   Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "#10 27.25      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 2.1 MB/s eta 0:00:00\n",
      "#10 28.01 Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r server_requirements.txt (line 4))\n",
      "#10 28.04   Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "#10 28.45      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 2.1 MB/s eta 0:00:00\n",
      "#10 28.57 Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r server_requirements.txt (line 4))\n",
      "#10 28.60   Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "#10 35.32      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 2.1 MB/s eta 0:00:00\n",
      "#10 35.82 Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r server_requirements.txt (line 4))\n",
      "#10 35.84   Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "#10 35.92 Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r server_requirements.txt (line 4))\n",
      "#10 35.95   Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
     ]
    }
   ],
   "source": [
    "run_model_server('bert_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd1d82c-2e9c-4420-a807-14f35ff347e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":\"Model load failed\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1:8080/v1/models/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016977f-d907-4f15-9b26-9177b1f34fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fcd58-dd55-4bea-b6e8-f84a631a38f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f952e4-2570-46a7-8565-73cad456938e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd8ecf-e124-49ac-bc29-459838173def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87541f2-cc1f-4049-8b83-1fb8696d6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b6e674-29f9-4ae0-82f3-45fcc17a98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizank/workspace/experiments/model_deployment_experiments/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    X = [[2],[3],[4]]\n",
    "    y = [4,6,8]\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    model_info = mlflow.sklearn.log_model(sk_model=lr, artifact_path=\"model\")\n",
    "    MODEL_URI = model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f93c81e-1067-454f-bbc0-3869053aa334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/3a98a956c3114efcbceb6cce54407227/model'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c360ee0-11e0-4356-b228-1cb7241a214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pyfunc = mlflow.pyfunc.load_model(model_uri=MODEL_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d2bbb4a-0bd7-430a-99c9-30ecb69ea579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_pyfunc.predict([[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b12726-4512-4253-8f12-fa6a9858b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c71202f95e4452a58229a61da28fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'apply_library_patches': True,\n",
      "            'base_image': None,\n",
      "            'bundled_packages_dir': 'packages',\n",
      "            'data_dir': 'data',\n",
      "            'description': None,\n",
      "            'environment_variables': {},\n",
      "            'examples_filename': 'examples.yaml',\n",
      "            'external_data': None,\n",
      "            'external_package_dirs': [],\n",
      "            'input_type': 'Any',\n",
      "            'live_reload': False,\n",
      "            'model_class_filename': 'model.py',\n",
      "            'model_class_name': 'Model',\n",
      "            'model_framework': <ModelFrameworkType.MLFLOW: 'mlflow'>,\n",
      "            'model_metadata': {'model_binary_dir': 'model',\n",
      "                               'supports_predict_proba': False},\n",
      "            'model_module_dir': 'model',\n",
      "            'model_name': None,\n",
      "            'model_type': 'Model',\n",
      "            'python_version': 'py310',\n",
      "            'requirements': ['mlflow==2.7.1',\n",
      "                             'cloudpickle==2.2.1',\n",
      "                             'numpy==1.23.5',\n",
      "                             'packaging==20.9',\n",
      "                             'psutil==5.9.6',\n",
      "                             'pyyaml==6.0.1',\n",
      "                             'scikit-learn==1.3.1',\n",
      "                             'scipy==1.11.3'],\n",
      "            'resources': Resources(cpu='500m',\n",
      "                                   memory='512Mi',\n",
      "                                   use_gpu=False,\n",
      "                                   accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                               count=0)),\n",
      "            'secrets': {},\n",
      "            'spec_version': '2.0',\n",
      "            'system_packages': [],\n",
      "            'train': Train(training_class_filename='train.py',\n",
      "                           training_class_name='Train',\n",
      "                           training_module_dir='train',\n",
      "                           variables={},\n",
      "                           resources=Resources(cpu='500m',\n",
      "                                               memory='512Mi',\n",
      "                                               use_gpu=False,\n",
      "                                               accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                                           count=0)))}}\n"
     ]
    }
   ],
   "source": [
    "save_model(sklearn_pyfunc, 'mlflow_sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73b83fb7-8171-4ac3-bf9b-4dd95e0d2fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [internal] load .dockerignore\n",
      "#1 transferring context: 2B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load build definition from Dockerfile\n",
      "#2 transferring dockerfile: 1.18kB done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/baseten/truss-server-base:3.9-v0.4.8\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [ 1/11] FROM docker.io/baseten/truss-server-base:3.9-v0.4.8\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 50.18kB done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [ 5/11] COPY ./requirements.txt requirements.txt\n",
      "#6 CACHED\n",
      "\n",
      "#7 [ 2/11] RUN grep -w 'ID=debian\\|ID_LIKE=debian' /etc/os-release || { echo \"ERROR: Supplied base image is not a debian image\"; exit 1; }\n",
      "#7 CACHED\n",
      "\n",
      "#8 [ 4/11] RUN pip install --upgrade pip --no-cache-dir     && rm -rf /root/.cache/pip\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ 6/11] RUN pip install -r requirements.txt --no-cache-dir && rm -rf /root/.cache/pip\n",
      "#9 CACHED\n",
      "\n",
      "#10 [ 3/11] RUN python3 -c \"import sys; sys.exit(0) if sys.version_info.major == 3 and sys.version_info.minor >=8 and sys.version_info.minor <=11 else sys.exit(1)\"     || { echo \"ERROR: Supplied base image does not have 3.8 <= python <= 3.11\"; exit 1; }\n",
      "#10 CACHED\n",
      "\n",
      "#11 [ 7/11] WORKDIR /app\n",
      "#11 CACHED\n",
      "\n",
      "#12 [ 8/11] COPY ./data /app/data\n",
      "#12 DONE 0.0s\n",
      "\n",
      "#13 [ 9/11] COPY ./server /app\n",
      "#13 DONE 0.0s\n",
      "\n",
      "#14 [10/11] COPY ./model /app/model\n",
      "#14 DONE 0.0s\n",
      "\n",
      "#15 [11/11] COPY ./config.yaml /app/config.yaml\n",
      "#15 DONE 0.0s\n",
      "\n",
      "#16 exporting to image\n",
      "#16 exporting layers 0.0s done\n",
      "#16 writing image sha256:d796eac9c9c60d207f74116f6b7b2dd0af4d8612c9fda50a65c431f8f6e11911 done\n",
      "#16 naming to docker.io/library/mlflow-model:latest done\n",
      "#16 DONE 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model server started on port 8080, docker container id db3f242454bb8704133af335d326960d93b4a0d17ed847ba726f8a9810decf76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:truss.truss_handle:Model server started on port 8080, docker container id db3f242454bb8704133af335d326960d93b4a0d17ed847ba726f8a9810decf76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container state: DockerStates.RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:truss.truss_handle:Container state: DockerStates.RUNNING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "python_on_whales.Container(id='db3f242454bb', name='elated_nightingale')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_server('mlflow_sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05c26c31-7bb0-4bf1-912c-14817018866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [4.000000000000001]}"
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1:8080/v1/models/model:predict -d '[[2]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33dcef95-ad5c-4de5-86e4-dd1ec87c32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slashdocker import stop_model_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27cea8d2-33e5-4519-9bd0-8732476bb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_model_server('db3f242454bb8704133af335d326960d93b4a0d17ed847ba726f8a9810decf76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bef9b-a78a-49f3-8a98-216631610703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559f4bf-ff35-44ea-ba39-cbecfd947b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b24969-a800-4589-aa2f-344466e28abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5cdf93-d84c-4320-8c6a-77648bbdac2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "405ff85c-6ac5-468c-beb9-e9258a1acacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ea7cbcc-d7d7-4b63-a561-789ae23d9083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1, 2.8, 4.7, 1.2],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [4.8, 3.1, 1.6, 0.2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50ee2aa4-748c-46ef-ace9-6272739135be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Truss uses XGBoost save/load which has a\n",
      "                different interface during inference than the class\n",
      "                you used to train this model. You can learn more about\n",
      "                these differences at\n",
      "                https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "                \u001b[0m\n",
      "{'config': {'apply_library_patches': True,\n",
      "            'base_image': None,\n",
      "            'bundled_packages_dir': 'packages',\n",
      "            'data_dir': 'data',\n",
      "            'description': None,\n",
      "            'environment_variables': {},\n",
      "            'examples_filename': 'examples.yaml',\n",
      "            'external_data': None,\n",
      "            'external_package_dirs': [],\n",
      "            'input_type': 'Any',\n",
      "            'live_reload': False,\n",
      "            'model_class_filename': 'model.py',\n",
      "            'model_class_name': 'Model',\n",
      "            'model_framework': <ModelFrameworkType.XGBOOST: 'xgboost'>,\n",
      "            'model_metadata': {'model_binary_dir': 'model',\n",
      "                               'supports_predict_proba': False},\n",
      "            'model_module_dir': 'model',\n",
      "            'model_name': None,\n",
      "            'model_type': 'Model',\n",
      "            'python_version': 'py310',\n",
      "            'requirements': ['xgboost==2.0.1'],\n",
      "            'resources': Resources(cpu='500m',\n",
      "                                   memory='512Mi',\n",
      "                                   use_gpu=False,\n",
      "                                   accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                               count=0)),\n",
      "            'secrets': {},\n",
      "            'spec_version': '2.0',\n",
      "            'system_packages': [],\n",
      "            'train': Train(training_class_filename='train.py',\n",
      "                           training_class_name='Train',\n",
      "                           training_module_dir='train',\n",
      "                           variables={},\n",
      "                           resources=Resources(cpu='500m',\n",
      "                                               memory='512Mi',\n",
      "                                               use_gpu=False,\n",
      "                                               accelerator=AcceleratorSpec(accelerator=None,\n",
      "                                                                           count=0)))}}\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82913475-40b7-4011-bfdd-1226f2e9cd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model server started on port 8080, docker container id fcb7a3beacb8bc6b26243affa10a348ef1bd9fe065a06dceb12e5fd4c3be76ab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:truss.truss_handle:Model server started on port 8080, docker container id fcb7a3beacb8bc6b26243affa10a348ef1bd9fe065a06dceb12e5fd4c3be76ab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container state: DockerStates.RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:truss.truss_handle:Container state: DockerStates.RUNNING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "python_on_whales.Container(id='fcb7a3beacb8', name='nervous_hofstadter')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_server('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "944e7272-c9d8-4eee-ab37-b6695e434dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [[0.0031177056953310966, 0.9867134094238281, 0.010168948210775852]]}"
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1:8080/v1/models/model:predict -d '[[6.1, 2.8, 4.7, 1.2]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962767c-a8ab-4b96-8340-a44fe4026384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
